1) I would expect the throughput to double due to parallelism of tasks in my dataflow graph. Latency would decrease
but not by double. So maybe latency wuld decrease around 1.3 or 1.5 times since not all tasks exhibit parallelism

2) For P = 1, the expected throughput was about 15 items/second. Which means with scaling, 100 items shoudl take 15 seconds, 
1000 should take 150 seconds, 10000 should take 1500 seconds, 100000 should take 15000 seconds and 1000000 shoudl take 
150000 seconds. However, looking at the observed throughput, the graph indicates that although input sizes of 1-1000 were close
to the expected throughput, when scaling to inputs sizes of 10,000 or 1,000,000 the expected throughput was much larger than the 
observed throughput. For example for 1,000,000 input size at Parallism 1, it processed only around 27,000 instead of 150,000. There
is a similar trend with the rest of the Parallism values, althought at P = 2 and P = 4, when scaling to higher input sizes, the 
observed throughput is higher to around 30,000 items/ second, but still not even close to the expected. For latency, the 
expected latency should be constant, around 10 seconds for each input size since data parallelism doesn't effect latency a whole lot.
Based on the observed this is mostly true, but again with input sizes of 10,000 or 1,000,000 latancy becomes around 70 seconds. The
same reains true for higher P values, except P = 2 which acutally only has a latency of around a minute. This is most likely
due to spark making partitions and keeping track of them.

3)